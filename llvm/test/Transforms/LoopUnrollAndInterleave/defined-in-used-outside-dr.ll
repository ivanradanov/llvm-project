; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 3
; RUN: opt -passes=loop-unroll-and-interleave %s -S --luai-factor=2 | FileCheck %s
; RUN: opt -passes=loop-unroll-and-interleave %s -S --luai-factor=2 --luai-use-dynamic-convergence=1 | FileCheck %s --check-prefix=DRCHECK

; void vecadd(int *a, int size) {
;   unsigned long j = size;
; #pragma omp target teams distribute parallel for map(tofrom: a[0:size]) //schedule(static, 4)
;   for (unsigned long i = 0; i < size; i++) {
;     int b = 0;
;     if (test1(i)) {
;       b = 1;
;       use1(a);
;     }
;     use1(b);
;   }
; }

target datalayout = "e-p:64:64-p1:64:64-p2:32:32-p3:32:32-p4:64:64-p5:32:32-p6:32:32-p7:160:256:256:32-p8:128:128-i64:64-v16:16-v24:32-v32:32-v48:64-v96:128-v192:256-v256:256-v512:512-v1024:1024-v2048:2048-n32:64-S32-A5-G1-ni:7:8"
target triple = "amdgcn-amd-amdhsa"

%struct.ident_t = type { i32, i32, i32, i32, ptr }
%struct.DynamicEnvironmentTy = type { i16 }
%struct.KernelEnvironmentTy = type { %struct.ConfigurationEnvironmentTy, ptr, ptr }
%struct.ConfigurationEnvironmentTy = type { i8, i8, i8 }

@__omp_rtl_debug_kind = weak_odr hidden local_unnamed_addr addrspace(1) constant i32 0
@__omp_rtl_assume_teams_oversubscription = weak_odr hidden local_unnamed_addr addrspace(1) constant i32 0
@__omp_rtl_assume_threads_oversubscription = weak_odr hidden local_unnamed_addr addrspace(1) constant i32 0
@__omp_rtl_assume_no_thread_state = weak_odr hidden local_unnamed_addr addrspace(1) constant i32 0
@__omp_rtl_assume_no_nested_parallelism = weak_odr hidden local_unnamed_addr addrspace(1) constant i32 0
@anon.c602dca16a57a4f518a4ba61482bb5a6.0 = private unnamed_addr constant [23 x i8] c";unknown;unknown;0;0;;\00", align 1
@anon.c602dca16a57a4f518a4ba61482bb5a6.1 = private unnamed_addr addrspace(1) constant %struct.ident_t { i32 0, i32 2, i32 0, i32 22, ptr @anon.c602dca16a57a4f518a4ba61482bb5a6.0 }, align 8
@__omp_offloading_58_36e080__Z6vecaddPii_l19_dynamic_environment = weak_odr protected addrspace(1) global %struct.DynamicEnvironmentTy zeroinitializer
@__omp_offloading_58_36e080__Z6vecaddPii_l19_kernel_environment = weak_odr protected addrspace(1) constant %struct.KernelEnvironmentTy { %struct.ConfigurationEnvironmentTy { i8 0, i8 1, i8 2 }, ptr addrspacecast (ptr addrspace(1) @anon.c602dca16a57a4f518a4ba61482bb5a6.1 to ptr), ptr addrspacecast (ptr addrspace(1) @__omp_offloading_58_36e080__Z6vecaddPii_l19_dynamic_environment to ptr) }
@anon.c602dca16a57a4f518a4ba61482bb5a6.2 = private unnamed_addr addrspace(1) constant %struct.ident_t { i32 0, i32 2050, i32 0, i32 22, ptr @anon.c602dca16a57a4f518a4ba61482bb5a6.0 }, align 8
@anon.c602dca16a57a4f518a4ba61482bb5a6.3 = private unnamed_addr addrspace(1) constant %struct.ident_t { i32 0, i32 514, i32 0, i32 22, ptr @anon.c602dca16a57a4f518a4ba61482bb5a6.0 }, align 8
@llvm.amdgcn.abi.version = weak_odr hidden local_unnamed_addr addrspace(4) constant i32 400

; Function Attrs: alwaysinline norecurse nounwind
define weak_odr protected amdgpu_kernel void @__omp_offloading_58_36e080__Z6vecaddPii_l19(i64 noundef %size, ptr noundef %a) local_unnamed_addr #0 {
; CHECK-LABEL: define weak_odr protected amdgpu_kernel void @__omp_offloading_58_36e080__Z6vecaddPii_l19(
; CHECK-SAME: i64 noundef [[SIZE:%.*]], ptr noundef [[A:%.*]]) local_unnamed_addr #[[ATTR0:[0-9]+]] {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[DOTOMP_COMB_LB_I:%.*]] = alloca i64, align 8, addrspace(5)
; CHECK-NEXT:    [[DOTOMP_COMB_UB_I:%.*]] = alloca i64, align 8, addrspace(5)
; CHECK-NEXT:    [[DOTOMP_STRIDE_I:%.*]] = alloca i64, align 8, addrspace(5)
; CHECK-NEXT:    [[DOTOMP_IS_LAST_I:%.*]] = alloca i32, align 4, addrspace(5)
; CHECK-NEXT:    [[CAPTURED_VARS_ADDRS_I:%.*]] = alloca [4 x ptr], align 8, addrspace(5)
; CHECK-NEXT:    [[TMP0:%.*]] = tail call i32 @__kmpc_target_init(ptr addrspacecast (ptr addrspace(1) @__omp_offloading_58_36e080__Z6vecaddPii_l19_kernel_environment to ptr)) #[[ATTR2:[0-9]+]]
; CHECK-NEXT:    [[EXEC_USER_CODE:%.*]] = icmp eq i32 [[TMP0]], -1
; CHECK-NEXT:    br i1 [[EXEC_USER_CODE]], label [[USER_CODE_ENTRY:%.*]], label [[COMMON_RET:%.*]]
; CHECK:       common.ret:
; CHECK-NEXT:    ret void
; CHECK:       user_code.entry:
; CHECK-NEXT:    [[TMP1:%.*]] = tail call i32 @__kmpc_global_thread_num(ptr addrspacecast (ptr addrspace(1) @anon.c602dca16a57a4f518a4ba61482bb5a6.1 to ptr)) #[[ATTR2]]
; CHECK-NEXT:    [[SIZE_CASTED_SROA_0_0_INSERT_EXT:%.*]] = and i64 [[SIZE]], 4294967295
; CHECK-NEXT:    call void @llvm.lifetime.start.p5(i64 32, ptr addrspace(5) [[CAPTURED_VARS_ADDRS_I]])
; CHECK-NEXT:    [[CAPTURED_VARS_ADDRS_ASCAST_I:%.*]] = addrspacecast ptr addrspace(5) [[CAPTURED_VARS_ADDRS_I]] to ptr
; CHECK-NEXT:    [[SEXT_I:%.*]] = shl nuw i64 [[SIZE_CASTED_SROA_0_0_INSERT_EXT]], 32
; CHECK-NEXT:    [[CONV_I:%.*]] = ashr exact i64 [[SEXT_I]], 32
; CHECK-NEXT:    [[SUB2_I:%.*]] = add nsw i64 [[CONV_I]], -1
; CHECK-NEXT:    [[CMP_NOT_I:%.*]] = icmp eq i64 [[SIZE_CASTED_SROA_0_0_INSERT_EXT]], 0
; CHECK-NEXT:    br i1 [[CMP_NOT_I]], label [[__OMP_OFFLOADING_58_36E080__Z6VECADDPII_L19_OMP_OUTLINED_EXIT:%.*]], label [[OMP_PRECOND_THEN_I:%.*]]
; CHECK:       omp.precond.then.i:
; CHECK-NEXT:    [[DOTOMP_STRIDE_ASCAST_I:%.*]] = addrspacecast ptr addrspace(5) [[DOTOMP_STRIDE_I]] to ptr
; CHECK-NEXT:    [[DOTOMP_COMB_UB_ASCAST_I:%.*]] = addrspacecast ptr addrspace(5) [[DOTOMP_COMB_UB_I]] to ptr
; CHECK-NEXT:    [[DOTOMP_COMB_LB_ASCAST_I:%.*]] = addrspacecast ptr addrspace(5) [[DOTOMP_COMB_LB_I]] to ptr
; CHECK-NEXT:    [[DOTOMP_IS_LAST_ASCAST_I:%.*]] = addrspacecast ptr addrspace(5) [[DOTOMP_IS_LAST_I]] to ptr
; CHECK-NEXT:    call void @llvm.lifetime.start.p5(i64 8, ptr addrspace(5) [[DOTOMP_COMB_LB_I]]) #[[ATTR7:[0-9]+]]
; CHECK-NEXT:    store i64 0, ptr addrspace(5) [[DOTOMP_COMB_LB_I]], align 8, !tbaa [[TBAA13:![0-9]+]]
; CHECK-NEXT:    call void @llvm.lifetime.start.p5(i64 8, ptr addrspace(5) [[DOTOMP_COMB_UB_I]]) #[[ATTR7]]
; CHECK-NEXT:    store i64 [[SUB2_I]], ptr addrspace(5) [[DOTOMP_COMB_UB_I]], align 8, !tbaa [[TBAA13]]
; CHECK-NEXT:    call void @llvm.lifetime.start.p5(i64 8, ptr addrspace(5) [[DOTOMP_STRIDE_I]]) #[[ATTR7]]
; CHECK-NEXT:    store i64 1, ptr addrspace(5) [[DOTOMP_STRIDE_I]], align 8, !tbaa [[TBAA13]]
; CHECK-NEXT:    call void @llvm.lifetime.start.p5(i64 4, ptr addrspace(5) [[DOTOMP_IS_LAST_I]]) #[[ATTR7]]
; CHECK-NEXT:    store i32 0, ptr addrspace(5) [[DOTOMP_IS_LAST_I]], align 4, !tbaa [[TBAA17:![0-9]+]]
; CHECK-NEXT:    call void @__kmpc_distribute_static_init_8u(ptr addrspacecast (ptr addrspace(1) @anon.c602dca16a57a4f518a4ba61482bb5a6.2 to ptr), i32 [[TMP1]], i32 91, ptr nocapture nonnull [[DOTOMP_IS_LAST_ASCAST_I]], ptr nocapture nonnull [[DOTOMP_COMB_LB_ASCAST_I]], ptr nocapture nonnull [[DOTOMP_COMB_UB_ASCAST_I]], ptr nocapture nonnull [[DOTOMP_STRIDE_ASCAST_I]], i64 1, i64 256) #[[ATTR2]]
; CHECK-NEXT:    [[DOTOMP_COMB_LB_PROMOTED_I:%.*]] = load i64, ptr addrspace(5) [[DOTOMP_COMB_LB_I]], align 8
; CHECK-NEXT:    [[CMP62_I:%.*]] = icmp ult i64 [[DOTOMP_COMB_LB_PROMOTED_I]], [[CONV_I]]
; CHECK-NEXT:    br i1 [[CMP62_I]], label [[OMP_INNER_FOR_BODY_LR_PH_I:%.*]], label [[OMP_LOOP_EXIT_I:%.*]]
; CHECK:       omp.inner.for.body.lr.ph.i:
; CHECK-NEXT:    [[TMP2:%.*]] = load i64, ptr addrspace(5) [[DOTOMP_COMB_UB_I]], align 8
; CHECK-NEXT:    [[COND_I:%.*]] = tail call i64 @llvm.umin.i64(i64 [[TMP2]], i64 [[SUB2_I]])
; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds [4 x ptr], ptr addrspace(5) [[CAPTURED_VARS_ADDRS_I]], i32 0, i32 1
; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds [4 x ptr], ptr addrspace(5) [[CAPTURED_VARS_ADDRS_I]], i32 0, i32 2
; CHECK-NEXT:    [[TMP5:%.*]] = inttoptr i64 [[SIZE_CASTED_SROA_0_0_INSERT_EXT]] to ptr
; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds [4 x ptr], ptr addrspace(5) [[CAPTURED_VARS_ADDRS_I]], i32 0, i32 3
; CHECK-NEXT:    [[TMP7:%.*]] = load i64, ptr addrspace(5) [[DOTOMP_STRIDE_I]], align 8
; CHECK-NEXT:    br label [[OMP_INNER_FOR_BODY_I:%.*]]
; CHECK:       omp.inner.for.body.i:
; CHECK-NEXT:    [[STOREMERGE4_I:%.*]] = phi i64 [ [[COND_I]], [[OMP_INNER_FOR_BODY_LR_PH_I]] ], [ [[COND14_I:%.*]], [[OMP_INNER_FOR_BODY_I]] ]
; CHECK-NEXT:    [[ADD813_I:%.*]] = phi i64 [ [[DOTOMP_COMB_LB_PROMOTED_I]], [[OMP_INNER_FOR_BODY_LR_PH_I]] ], [ [[ADD8_I:%.*]], [[OMP_INNER_FOR_BODY_I]] ]
; CHECK-NEXT:    [[TMP8:%.*]] = inttoptr i64 [[ADD813_I]] to ptr
; CHECK-NEXT:    store ptr [[TMP8]], ptr addrspace(5) [[CAPTURED_VARS_ADDRS_I]], align 8, !tbaa [[TBAA19:![0-9]+]]
; CHECK-NEXT:    [[TMP9:%.*]] = inttoptr i64 [[STOREMERGE4_I]] to ptr
; CHECK-NEXT:    store ptr [[TMP9]], ptr addrspace(5) [[TMP3]], align 8, !tbaa [[TBAA19]]
; CHECK-NEXT:    store ptr [[TMP5]], ptr addrspace(5) [[TMP4]], align 8, !tbaa [[TBAA19]]
; CHECK-NEXT:    store ptr [[A]], ptr addrspace(5) [[TMP6]], align 8, !tbaa [[TBAA19]]
; CHECK-NEXT:    call void @__kmpc_parallel_51(ptr addrspacecast (ptr addrspace(1) @anon.c602dca16a57a4f518a4ba61482bb5a6.1 to ptr), i32 [[TMP1]], i32 1, i32 -1, i32 -1, ptr nonnull @__omp_offloading_58_36e080__Z6vecaddPii_l19_omp_outlined_omp_outlined, ptr null, ptr nonnull [[CAPTURED_VARS_ADDRS_ASCAST_I]], i64 4) #[[ATTR2]]
; CHECK-NEXT:    [[ADD8_I]] = add i64 [[ADD813_I]], [[TMP7]]
; CHECK-NEXT:    [[ADD9_I:%.*]] = add i64 [[STOREMERGE4_I]], [[TMP7]]
; CHECK-NEXT:    [[COND14_I]] = call i64 @llvm.umin.i64(i64 [[ADD9_I]], i64 [[SUB2_I]])
; CHECK-NEXT:    [[CMP6_I:%.*]] = icmp ult i64 [[ADD8_I]], [[CONV_I]]
; CHECK-NEXT:    br i1 [[CMP6_I]], label [[OMP_INNER_FOR_BODY_I]], label [[OMP_LOOP_EXIT_I_LOOPEXIT:%.*]]
; CHECK:       omp.loop.exit.i.loopexit:
; CHECK-NEXT:    br label [[OMP_LOOP_EXIT_I]]
; CHECK:       omp.loop.exit.i:
; CHECK-NEXT:    call void @__kmpc_distribute_static_fini(ptr addrspacecast (ptr addrspace(1) @anon.c602dca16a57a4f518a4ba61482bb5a6.2 to ptr), i32 [[TMP1]]) #[[ATTR2]]
; CHECK-NEXT:    br label [[__OMP_OFFLOADING_58_36E080__Z6VECADDPII_L19_OMP_OUTLINED_EXIT]]
; CHECK:       __omp_offloading_58_36e080__Z6vecaddPii_l19_omp_outlined.exit:
; CHECK-NEXT:    call void @llvm.lifetime.end.p5(i64 4, ptr addrspace(5) [[DOTOMP_IS_LAST_I]]) #[[ATTR2]]
; CHECK-NEXT:    call void @llvm.lifetime.end.p5(i64 8, ptr addrspace(5) [[DOTOMP_STRIDE_I]]) #[[ATTR2]]
; CHECK-NEXT:    call void @llvm.lifetime.end.p5(i64 8, ptr addrspace(5) [[DOTOMP_COMB_UB_I]]) #[[ATTR2]]
; CHECK-NEXT:    call void @llvm.lifetime.end.p5(i64 8, ptr addrspace(5) [[DOTOMP_COMB_LB_I]]) #[[ATTR2]]
; CHECK-NEXT:    call void @llvm.lifetime.end.p5(i64 32, ptr addrspace(5) [[CAPTURED_VARS_ADDRS_I]])
; CHECK-NEXT:    call void @__kmpc_target_deinit() #[[ATTR2]]
; CHECK-NEXT:    br label [[COMMON_RET]]
;
; DRCHECK-LABEL: define weak_odr protected amdgpu_kernel void @__omp_offloading_58_36e080__Z6vecaddPii_l19(
; DRCHECK-SAME: i64 noundef [[SIZE:%.*]], ptr noundef [[A:%.*]]) local_unnamed_addr #[[ATTR0:[0-9]+]] {
; DRCHECK-NEXT:  entry:
; DRCHECK-NEXT:    [[DOTOMP_COMB_LB_I:%.*]] = alloca i64, align 8, addrspace(5)
; DRCHECK-NEXT:    [[DOTOMP_COMB_UB_I:%.*]] = alloca i64, align 8, addrspace(5)
; DRCHECK-NEXT:    [[DOTOMP_STRIDE_I:%.*]] = alloca i64, align 8, addrspace(5)
; DRCHECK-NEXT:    [[DOTOMP_IS_LAST_I:%.*]] = alloca i32, align 4, addrspace(5)
; DRCHECK-NEXT:    [[CAPTURED_VARS_ADDRS_I:%.*]] = alloca [4 x ptr], align 8, addrspace(5)
; DRCHECK-NEXT:    [[TMP0:%.*]] = tail call i32 @__kmpc_target_init(ptr addrspacecast (ptr addrspace(1) @__omp_offloading_58_36e080__Z6vecaddPii_l19_kernel_environment to ptr)) #[[ATTR2:[0-9]+]]
; DRCHECK-NEXT:    [[EXEC_USER_CODE:%.*]] = icmp eq i32 [[TMP0]], -1
; DRCHECK-NEXT:    br i1 [[EXEC_USER_CODE]], label [[USER_CODE_ENTRY:%.*]], label [[COMMON_RET:%.*]]
; DRCHECK:       common.ret:
; DRCHECK-NEXT:    ret void
; DRCHECK:       user_code.entry:
; DRCHECK-NEXT:    [[TMP1:%.*]] = tail call i32 @__kmpc_global_thread_num(ptr addrspacecast (ptr addrspace(1) @anon.c602dca16a57a4f518a4ba61482bb5a6.1 to ptr)) #[[ATTR2]]
; DRCHECK-NEXT:    [[SIZE_CASTED_SROA_0_0_INSERT_EXT:%.*]] = and i64 [[SIZE]], 4294967295
; DRCHECK-NEXT:    call void @llvm.lifetime.start.p5(i64 32, ptr addrspace(5) [[CAPTURED_VARS_ADDRS_I]])
; DRCHECK-NEXT:    [[CAPTURED_VARS_ADDRS_ASCAST_I:%.*]] = addrspacecast ptr addrspace(5) [[CAPTURED_VARS_ADDRS_I]] to ptr
; DRCHECK-NEXT:    [[SEXT_I:%.*]] = shl nuw i64 [[SIZE_CASTED_SROA_0_0_INSERT_EXT]], 32
; DRCHECK-NEXT:    [[CONV_I:%.*]] = ashr exact i64 [[SEXT_I]], 32
; DRCHECK-NEXT:    [[SUB2_I:%.*]] = add nsw i64 [[CONV_I]], -1
; DRCHECK-NEXT:    [[CMP_NOT_I:%.*]] = icmp eq i64 [[SIZE_CASTED_SROA_0_0_INSERT_EXT]], 0
; DRCHECK-NEXT:    br i1 [[CMP_NOT_I]], label [[__OMP_OFFLOADING_58_36E080__Z6VECADDPII_L19_OMP_OUTLINED_EXIT:%.*]], label [[OMP_PRECOND_THEN_I:%.*]]
; DRCHECK:       omp.precond.then.i:
; DRCHECK-NEXT:    [[DOTOMP_STRIDE_ASCAST_I:%.*]] = addrspacecast ptr addrspace(5) [[DOTOMP_STRIDE_I]] to ptr
; DRCHECK-NEXT:    [[DOTOMP_COMB_UB_ASCAST_I:%.*]] = addrspacecast ptr addrspace(5) [[DOTOMP_COMB_UB_I]] to ptr
; DRCHECK-NEXT:    [[DOTOMP_COMB_LB_ASCAST_I:%.*]] = addrspacecast ptr addrspace(5) [[DOTOMP_COMB_LB_I]] to ptr
; DRCHECK-NEXT:    [[DOTOMP_IS_LAST_ASCAST_I:%.*]] = addrspacecast ptr addrspace(5) [[DOTOMP_IS_LAST_I]] to ptr
; DRCHECK-NEXT:    call void @llvm.lifetime.start.p5(i64 8, ptr addrspace(5) [[DOTOMP_COMB_LB_I]]) #[[ATTR7:[0-9]+]]
; DRCHECK-NEXT:    store i64 0, ptr addrspace(5) [[DOTOMP_COMB_LB_I]], align 8, !tbaa [[TBAA13:![0-9]+]]
; DRCHECK-NEXT:    call void @llvm.lifetime.start.p5(i64 8, ptr addrspace(5) [[DOTOMP_COMB_UB_I]]) #[[ATTR7]]
; DRCHECK-NEXT:    store i64 [[SUB2_I]], ptr addrspace(5) [[DOTOMP_COMB_UB_I]], align 8, !tbaa [[TBAA13]]
; DRCHECK-NEXT:    call void @llvm.lifetime.start.p5(i64 8, ptr addrspace(5) [[DOTOMP_STRIDE_I]]) #[[ATTR7]]
; DRCHECK-NEXT:    store i64 1, ptr addrspace(5) [[DOTOMP_STRIDE_I]], align 8, !tbaa [[TBAA13]]
; DRCHECK-NEXT:    call void @llvm.lifetime.start.p5(i64 4, ptr addrspace(5) [[DOTOMP_IS_LAST_I]]) #[[ATTR7]]
; DRCHECK-NEXT:    store i32 0, ptr addrspace(5) [[DOTOMP_IS_LAST_I]], align 4, !tbaa [[TBAA17:![0-9]+]]
; DRCHECK-NEXT:    call void @__kmpc_distribute_static_init_8u(ptr addrspacecast (ptr addrspace(1) @anon.c602dca16a57a4f518a4ba61482bb5a6.2 to ptr), i32 [[TMP1]], i32 91, ptr nocapture nonnull [[DOTOMP_IS_LAST_ASCAST_I]], ptr nocapture nonnull [[DOTOMP_COMB_LB_ASCAST_I]], ptr nocapture nonnull [[DOTOMP_COMB_UB_ASCAST_I]], ptr nocapture nonnull [[DOTOMP_STRIDE_ASCAST_I]], i64 1, i64 256) #[[ATTR2]]
; DRCHECK-NEXT:    [[DOTOMP_COMB_LB_PROMOTED_I:%.*]] = load i64, ptr addrspace(5) [[DOTOMP_COMB_LB_I]], align 8
; DRCHECK-NEXT:    [[CMP62_I:%.*]] = icmp ult i64 [[DOTOMP_COMB_LB_PROMOTED_I]], [[CONV_I]]
; DRCHECK-NEXT:    br i1 [[CMP62_I]], label [[OMP_INNER_FOR_BODY_LR_PH_I:%.*]], label [[OMP_LOOP_EXIT_I:%.*]]
; DRCHECK:       omp.inner.for.body.lr.ph.i:
; DRCHECK-NEXT:    [[TMP2:%.*]] = load i64, ptr addrspace(5) [[DOTOMP_COMB_UB_I]], align 8
; DRCHECK-NEXT:    [[COND_I:%.*]] = tail call i64 @llvm.umin.i64(i64 [[TMP2]], i64 [[SUB2_I]])
; DRCHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds [4 x ptr], ptr addrspace(5) [[CAPTURED_VARS_ADDRS_I]], i32 0, i32 1
; DRCHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds [4 x ptr], ptr addrspace(5) [[CAPTURED_VARS_ADDRS_I]], i32 0, i32 2
; DRCHECK-NEXT:    [[TMP5:%.*]] = inttoptr i64 [[SIZE_CASTED_SROA_0_0_INSERT_EXT]] to ptr
; DRCHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds [4 x ptr], ptr addrspace(5) [[CAPTURED_VARS_ADDRS_I]], i32 0, i32 3
; DRCHECK-NEXT:    [[TMP7:%.*]] = load i64, ptr addrspace(5) [[DOTOMP_STRIDE_I]], align 8
; DRCHECK-NEXT:    br label [[OMP_INNER_FOR_BODY_I:%.*]]
; DRCHECK:       omp.inner.for.body.i:
; DRCHECK-NEXT:    [[STOREMERGE4_I:%.*]] = phi i64 [ [[COND_I]], [[OMP_INNER_FOR_BODY_LR_PH_I]] ], [ [[COND14_I:%.*]], [[OMP_INNER_FOR_BODY_I]] ]
; DRCHECK-NEXT:    [[ADD813_I:%.*]] = phi i64 [ [[DOTOMP_COMB_LB_PROMOTED_I]], [[OMP_INNER_FOR_BODY_LR_PH_I]] ], [ [[ADD8_I:%.*]], [[OMP_INNER_FOR_BODY_I]] ]
; DRCHECK-NEXT:    [[TMP8:%.*]] = inttoptr i64 [[ADD813_I]] to ptr
; DRCHECK-NEXT:    store ptr [[TMP8]], ptr addrspace(5) [[CAPTURED_VARS_ADDRS_I]], align 8, !tbaa [[TBAA19:![0-9]+]]
; DRCHECK-NEXT:    [[TMP9:%.*]] = inttoptr i64 [[STOREMERGE4_I]] to ptr
; DRCHECK-NEXT:    store ptr [[TMP9]], ptr addrspace(5) [[TMP3]], align 8, !tbaa [[TBAA19]]
; DRCHECK-NEXT:    store ptr [[TMP5]], ptr addrspace(5) [[TMP4]], align 8, !tbaa [[TBAA19]]
; DRCHECK-NEXT:    store ptr [[A]], ptr addrspace(5) [[TMP6]], align 8, !tbaa [[TBAA19]]
; DRCHECK-NEXT:    call void @__kmpc_parallel_51(ptr addrspacecast (ptr addrspace(1) @anon.c602dca16a57a4f518a4ba61482bb5a6.1 to ptr), i32 [[TMP1]], i32 1, i32 -1, i32 -1, ptr nonnull @__omp_offloading_58_36e080__Z6vecaddPii_l19_omp_outlined_omp_outlined, ptr null, ptr nonnull [[CAPTURED_VARS_ADDRS_ASCAST_I]], i64 4) #[[ATTR2]]
; DRCHECK-NEXT:    [[ADD8_I]] = add i64 [[ADD813_I]], [[TMP7]]
; DRCHECK-NEXT:    [[ADD9_I:%.*]] = add i64 [[STOREMERGE4_I]], [[TMP7]]
; DRCHECK-NEXT:    [[COND14_I]] = call i64 @llvm.umin.i64(i64 [[ADD9_I]], i64 [[SUB2_I]])
; DRCHECK-NEXT:    [[CMP6_I:%.*]] = icmp ult i64 [[ADD8_I]], [[CONV_I]]
; DRCHECK-NEXT:    br i1 [[CMP6_I]], label [[OMP_INNER_FOR_BODY_I]], label [[OMP_LOOP_EXIT_I_LOOPEXIT:%.*]]
; DRCHECK:       omp.loop.exit.i.loopexit:
; DRCHECK-NEXT:    br label [[OMP_LOOP_EXIT_I]]
; DRCHECK:       omp.loop.exit.i:
; DRCHECK-NEXT:    call void @__kmpc_distribute_static_fini(ptr addrspacecast (ptr addrspace(1) @anon.c602dca16a57a4f518a4ba61482bb5a6.2 to ptr), i32 [[TMP1]]) #[[ATTR2]]
; DRCHECK-NEXT:    br label [[__OMP_OFFLOADING_58_36E080__Z6VECADDPII_L19_OMP_OUTLINED_EXIT]]
; DRCHECK:       __omp_offloading_58_36e080__Z6vecaddPii_l19_omp_outlined.exit:
; DRCHECK-NEXT:    call void @llvm.lifetime.end.p5(i64 4, ptr addrspace(5) [[DOTOMP_IS_LAST_I]]) #[[ATTR2]]
; DRCHECK-NEXT:    call void @llvm.lifetime.end.p5(i64 8, ptr addrspace(5) [[DOTOMP_STRIDE_I]]) #[[ATTR2]]
; DRCHECK-NEXT:    call void @llvm.lifetime.end.p5(i64 8, ptr addrspace(5) [[DOTOMP_COMB_UB_I]]) #[[ATTR2]]
; DRCHECK-NEXT:    call void @llvm.lifetime.end.p5(i64 8, ptr addrspace(5) [[DOTOMP_COMB_LB_I]]) #[[ATTR2]]
; DRCHECK-NEXT:    call void @llvm.lifetime.end.p5(i64 32, ptr addrspace(5) [[CAPTURED_VARS_ADDRS_I]])
; DRCHECK-NEXT:    call void @__kmpc_target_deinit() #[[ATTR2]]
; DRCHECK-NEXT:    br label [[COMMON_RET]]
;
entry:
  %.omp.comb.lb.i = alloca i64, align 8, addrspace(5)
  %.omp.comb.ub.i = alloca i64, align 8, addrspace(5)
  %.omp.stride.i = alloca i64, align 8, addrspace(5)
  %.omp.is_last.i = alloca i32, align 4, addrspace(5)
  %captured_vars_addrs.i = alloca [4 x ptr], align 8, addrspace(5)
  %0 = tail call i32 @__kmpc_target_init(ptr addrspacecast (ptr addrspace(1) @__omp_offloading_58_36e080__Z6vecaddPii_l19_kernel_environment to ptr)) #2
  %exec_user_code = icmp eq i32 %0, -1
  br i1 %exec_user_code, label %user_code.entry, label %common.ret

common.ret:                                       ; preds = %__omp_offloading_58_36e080__Z6vecaddPii_l19_omp_outlined.exit, %entry
  ret void

user_code.entry:                                  ; preds = %entry
  %1 = tail call i32 @__kmpc_global_thread_num(ptr addrspacecast (ptr addrspace(1) @anon.c602dca16a57a4f518a4ba61482bb5a6.1 to ptr)) #2
  %size.casted.sroa.0.0.insert.ext = and i64 %size, 4294967295
  call void @llvm.lifetime.start.p5(i64 32, ptr addrspace(5) %captured_vars_addrs.i)
  %captured_vars_addrs.ascast.i = addrspacecast ptr addrspace(5) %captured_vars_addrs.i to ptr
  %sext.i = shl nuw i64 %size.casted.sroa.0.0.insert.ext, 32
  %conv.i = ashr exact i64 %sext.i, 32
  %sub2.i = add nsw i64 %conv.i, -1
  %cmp.not.i = icmp eq i64 %size.casted.sroa.0.0.insert.ext, 0
  br i1 %cmp.not.i, label %__omp_offloading_58_36e080__Z6vecaddPii_l19_omp_outlined.exit, label %omp.precond.then.i

omp.precond.then.i:                               ; preds = %user_code.entry
  %.omp.stride.ascast.i = addrspacecast ptr addrspace(5) %.omp.stride.i to ptr
  %.omp.comb.ub.ascast.i = addrspacecast ptr addrspace(5) %.omp.comb.ub.i to ptr
  %.omp.comb.lb.ascast.i = addrspacecast ptr addrspace(5) %.omp.comb.lb.i to ptr
  %.omp.is_last.ascast.i = addrspacecast ptr addrspace(5) %.omp.is_last.i to ptr
  call void @llvm.lifetime.start.p5(i64 8, ptr addrspace(5) %.omp.comb.lb.i) #7
  store i64 0, ptr addrspace(5) %.omp.comb.lb.i, align 8, !tbaa !13
  call void @llvm.lifetime.start.p5(i64 8, ptr addrspace(5) %.omp.comb.ub.i) #7
  store i64 %sub2.i, ptr addrspace(5) %.omp.comb.ub.i, align 8, !tbaa !13
  call void @llvm.lifetime.start.p5(i64 8, ptr addrspace(5) %.omp.stride.i) #7
  store i64 1, ptr addrspace(5) %.omp.stride.i, align 8, !tbaa !13
  call void @llvm.lifetime.start.p5(i64 4, ptr addrspace(5) %.omp.is_last.i) #7
  store i32 0, ptr addrspace(5) %.omp.is_last.i, align 4, !tbaa !17
  call void @__kmpc_distribute_static_init_8u(ptr addrspacecast (ptr addrspace(1) @anon.c602dca16a57a4f518a4ba61482bb5a6.2 to ptr), i32 %1, i32 91, ptr nocapture nonnull %.omp.is_last.ascast.i, ptr nocapture nonnull %.omp.comb.lb.ascast.i, ptr nocapture nonnull %.omp.comb.ub.ascast.i, ptr nocapture nonnull %.omp.stride.ascast.i, i64 1, i64 256) #2
  %.omp.comb.lb.promoted.i = load i64, ptr addrspace(5) %.omp.comb.lb.i, align 8
  %cmp62.i = icmp ult i64 %.omp.comb.lb.promoted.i, %conv.i
  br i1 %cmp62.i, label %omp.inner.for.body.lr.ph.i, label %omp.loop.exit.i

omp.inner.for.body.lr.ph.i:                       ; preds = %omp.precond.then.i
  %2 = load i64, ptr addrspace(5) %.omp.comb.ub.i, align 8
  %cond.i = tail call i64 @llvm.umin.i64(i64 %2, i64 %sub2.i)
  %3 = getelementptr inbounds [4 x ptr], ptr addrspace(5) %captured_vars_addrs.i, i32 0, i32 1
  %4 = getelementptr inbounds [4 x ptr], ptr addrspace(5) %captured_vars_addrs.i, i32 0, i32 2
  %5 = inttoptr i64 %size.casted.sroa.0.0.insert.ext to ptr
  %6 = getelementptr inbounds [4 x ptr], ptr addrspace(5) %captured_vars_addrs.i, i32 0, i32 3
  %7 = load i64, ptr addrspace(5) %.omp.stride.i, align 8
  br label %omp.inner.for.body.i

omp.inner.for.body.i:                             ; preds = %omp.inner.for.body.i, %omp.inner.for.body.lr.ph.i
  %storemerge4.i = phi i64 [ %cond.i, %omp.inner.for.body.lr.ph.i ], [ %cond14.i, %omp.inner.for.body.i ]
  %add813.i = phi i64 [ %.omp.comb.lb.promoted.i, %omp.inner.for.body.lr.ph.i ], [ %add8.i, %omp.inner.for.body.i ]
  %8 = inttoptr i64 %add813.i to ptr
  store ptr %8, ptr addrspace(5) %captured_vars_addrs.i, align 8, !tbaa !19
  %9 = inttoptr i64 %storemerge4.i to ptr
  store ptr %9, ptr addrspace(5) %3, align 8, !tbaa !19
  store ptr %5, ptr addrspace(5) %4, align 8, !tbaa !19
  store ptr %a, ptr addrspace(5) %6, align 8, !tbaa !19
  call void @__kmpc_parallel_51(ptr addrspacecast (ptr addrspace(1) @anon.c602dca16a57a4f518a4ba61482bb5a6.1 to ptr), i32 %1, i32 1, i32 -1, i32 -1, ptr nonnull @__omp_offloading_58_36e080__Z6vecaddPii_l19_omp_outlined_omp_outlined, ptr null, ptr nonnull %captured_vars_addrs.ascast.i, i64 4) #2
  %add8.i = add i64 %add813.i, %7
  %add9.i = add i64 %storemerge4.i, %7
  %cond14.i = call i64 @llvm.umin.i64(i64 %add9.i, i64 %sub2.i)
  %cmp6.i = icmp ult i64 %add8.i, %conv.i
  br i1 %cmp6.i, label %omp.inner.for.body.i, label %omp.loop.exit.i

omp.loop.exit.i:                                  ; preds = %omp.inner.for.body.i, %omp.precond.then.i
  call void @__kmpc_distribute_static_fini(ptr addrspacecast (ptr addrspace(1) @anon.c602dca16a57a4f518a4ba61482bb5a6.2 to ptr), i32 %1) #2
  br label %__omp_offloading_58_36e080__Z6vecaddPii_l19_omp_outlined.exit

__omp_offloading_58_36e080__Z6vecaddPii_l19_omp_outlined.exit: ; preds = %omp.loop.exit.i, %user_code.entry
  call void @llvm.lifetime.end.p5(i64 4, ptr addrspace(5) %.omp.is_last.i) #2
  call void @llvm.lifetime.end.p5(i64 8, ptr addrspace(5) %.omp.stride.i) #2
  call void @llvm.lifetime.end.p5(i64 8, ptr addrspace(5) %.omp.comb.ub.i) #2
  call void @llvm.lifetime.end.p5(i64 8, ptr addrspace(5) %.omp.comb.lb.i) #2
  call void @llvm.lifetime.end.p5(i64 32, ptr addrspace(5) %captured_vars_addrs.i)
  call void @__kmpc_target_deinit() #2
  br label %common.ret
}

declare i32 @__kmpc_target_init(ptr) local_unnamed_addr

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(argmem: readwrite)
declare void @llvm.lifetime.start.p5(i64 immarg, ptr addrspace(5) nocapture) #1

; Function Attrs: nocallback nofree nosync nounwind willreturn memory(argmem: readwrite)
declare void @llvm.lifetime.end.p5(i64 immarg, ptr addrspace(5) nocapture) #1

; Function Attrs: nounwind
declare void @__kmpc_distribute_static_init_8u(ptr, i32, i32, ptr nocapture nofree, ptr nocapture nofree, ptr nocapture nofree, ptr nocapture nofree, i64, i64) local_unnamed_addr #2

; Function Attrs: alwaysinline convergent norecurse nounwind
define internal void @__omp_offloading_58_36e080__Z6vecaddPii_l19_omp_outlined_omp_outlined(ptr noalias nocapture noundef readonly %.global_tid., ptr noalias nocapture readnone %.bound_tid., i64 noundef %.previous.lb., i64 noundef %.previous.ub., i64 noundef %size, ptr noundef %a) #3 {
; CHECK-LABEL: define internal void @__omp_offloading_58_36e080__Z6vecaddPii_l19_omp_outlined_omp_outlined(
; CHECK-SAME: ptr noalias nocapture noundef readonly [[DOTGLOBAL_TID_:%.*]], ptr noalias nocapture readnone [[DOTBOUND_TID_:%.*]], i64 noundef [[DOTPREVIOUS_LB_:%.*]], i64 noundef [[DOTPREVIOUS_UB_:%.*]], i64 noundef [[SIZE:%.*]], ptr noundef [[A:%.*]]) #[[ATTR3:[0-9]+]] {
; CHECK-NEXT:  entry:
; CHECK-NEXT:    [[DOTOMP_LB:%.*]] = alloca i64, align 8, addrspace(5)
; CHECK-NEXT:    [[DOTOMP_UB:%.*]] = alloca i64, align 8, addrspace(5)
; CHECK-NEXT:    [[DOTOMP_STRIDE:%.*]] = alloca i64, align 8, addrspace(5)
; CHECK-NEXT:    [[DOTOMP_IS_LAST:%.*]] = alloca i32, align 4, addrspace(5)
; CHECK-NEXT:    [[SEXT_MASK:%.*]] = and i64 [[SIZE]], 4294967295
; CHECK-NEXT:    [[CMP_NOT:%.*]] = icmp eq i64 [[SEXT_MASK]], 0
; CHECK-NEXT:    br i1 [[CMP_NOT]], label [[OMP_PRECOND_END:%.*]], label [[OMP_PRECOND_THEN:%.*]]
; CHECK:       omp.precond.then:
; CHECK-NEXT:    [[DOTOMP_STRIDE_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTOMP_STRIDE]] to ptr
; CHECK-NEXT:    [[DOTOMP_IS_LAST_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTOMP_IS_LAST]] to ptr
; CHECK-NEXT:    [[DOTOMP_UB_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTOMP_UB]] to ptr
; CHECK-NEXT:    [[DOTOMP_LB_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTOMP_LB]] to ptr
; CHECK-NEXT:    call void @llvm.lifetime.start.p5(i64 8, ptr addrspace(5) [[DOTOMP_LB]]) #[[ATTR2]]
; CHECK-NEXT:    call void @llvm.lifetime.start.p5(i64 8, ptr addrspace(5) [[DOTOMP_UB]]) #[[ATTR2]]
; CHECK-NEXT:    store i64 [[DOTPREVIOUS_LB_]], ptr addrspace(5) [[DOTOMP_LB]], align 8, !tbaa [[TBAA13]]
; CHECK-NEXT:    store i64 [[DOTPREVIOUS_UB_]], ptr addrspace(5) [[DOTOMP_UB]], align 8, !tbaa [[TBAA13]]
; CHECK-NEXT:    call void @llvm.lifetime.start.p5(i64 8, ptr addrspace(5) [[DOTOMP_STRIDE]]) #[[ATTR2]]
; CHECK-NEXT:    store i64 1, ptr addrspace(5) [[DOTOMP_STRIDE]], align 8, !tbaa [[TBAA13]]
; CHECK-NEXT:    call void @llvm.lifetime.start.p5(i64 4, ptr addrspace(5) [[DOTOMP_IS_LAST]]) #[[ATTR2]]
; CHECK-NEXT:    store i32 0, ptr addrspace(5) [[DOTOMP_IS_LAST]], align 4, !tbaa [[TBAA17]]
; CHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[DOTGLOBAL_TID_]], align 4, !tbaa [[TBAA17]]
; CHECK-NEXT:    call void @__kmpc_for_static_init_8u(ptr addrspacecast (ptr addrspace(1) @anon.c602dca16a57a4f518a4ba61482bb5a6.3 to ptr), i32 [[TMP0]], i32 33, ptr nocapture nonnull [[DOTOMP_IS_LAST_ASCAST]], ptr nocapture nonnull [[DOTOMP_LB_ASCAST]], ptr nocapture nonnull [[DOTOMP_UB_ASCAST]], ptr nocapture nonnull [[DOTOMP_STRIDE_ASCAST]], i64 1, i64 1) #[[ATTR2]]
; CHECK-NEXT:    [[TMP1:%.*]] = load i64, ptr addrspace(5) [[DOTOMP_LB]], align 8, !tbaa [[TBAA13]]
; CHECK-NEXT:    [[ADD:%.*]] = add i64 [[DOTPREVIOUS_UB_]], 1
; CHECK-NEXT:    [[CMP413:%.*]] = icmp ult i64 [[TMP1]], [[ADD]]
; CHECK-NEXT:    br i1 [[CMP413]], label [[OMP_INNER_FOR_BODY_LR_PH:%.*]], label [[OMP_LOOP_EXIT:%.*]]
; CHECK:       omp.inner.for.body.lr.ph:
; CHECK-NEXT:    [[TMP2:%.*]] = load i64, ptr addrspace(5) [[DOTOMP_STRIDE]], align 8
; CHECK-NEXT:    [[INITIAL_IV_COARSENED_1:%.*]] = add i64 [[TMP2]], [[TMP1]]
; CHECK-NEXT:    [[COARSENED_STEP:%.*]] = mul i64 [[TMP2]], 2
; CHECK-NEXT:    [[TMP3:%.*]] = sub i64 [[ADD]], [[TMP1]]
; CHECK-NEXT:    [[TMP4:%.*]] = add i64 [[TMP3]], [[TMP2]]
; CHECK-NEXT:    [[TMP5:%.*]] = sub i64 [[TMP4]], 1
; CHECK-NEXT:    [[TMP6:%.*]] = udiv i64 [[TMP5]], [[TMP2]]
; CHECK-NEXT:    [[TMP7:%.*]] = udiv i64 [[TMP6]], 2
; CHECK-NEXT:    [[TMP8:%.*]] = mul nsw i64 [[TMP7]], 2
; CHECK-NEXT:    [[TMP9:%.*]] = mul nsw i64 [[TMP8]], [[TMP2]]
; CHECK-NEXT:    [[EPILOGUE_START_IV:%.*]] = add i64 [[TMP9]], [[TMP1]]
; CHECK-NEXT:    [[IS_EPILOGUE_START:%.*]] = icmp eq i64 [[TMP1]], [[EPILOGUE_START_IV]]
; CHECK-NEXT:    br i1 [[IS_EPILOGUE_START]], label [[OMP_INNER_FOR_BODY_EPILOGUE:%.*]], label [[OMP_INNER_FOR_BODY:%.*]]
; CHECK:       omp.inner.for.body:
; CHECK-NEXT:    [[B_0_REG2MEM_0:%.*]] = phi i32 [ undef, [[OMP_INNER_FOR_BODY_LR_PH]] ], [ [[B_0_REG2MEM_1:%.*]], [[IF_END:%.*]] ]
; CHECK-NEXT:    [[DOTOMP_IV_014:%.*]] = phi i64 [ [[TMP1]], [[OMP_INNER_FOR_BODY_LR_PH]] ], [ [[TMP10:%.*]], [[IF_END]] ]
; CHECK-NEXT:    [[DOTOMP_IV_014_COARSENED_1:%.*]] = phi i64 [ [[INITIAL_IV_COARSENED_1]], [[OMP_INNER_FOR_BODY_LR_PH]] ], [ [[DOTCOARSENED_1:%.*]], [[IF_END]] ]
; CHECK-NEXT:    [[CONV6:%.*]] = trunc i64 [[DOTOMP_IV_014]] to i32
; CHECK-NEXT:    [[CONV6_COARSENED_1:%.*]] = trunc i64 [[DOTOMP_IV_014_COARSENED_1]] to i32
; CHECK-NEXT:    [[CALL:%.*]] = tail call noundef zeroext i1 @_Z5test1i(i32 noundef [[CONV6]]) #[[ATTR8:[0-9]+]]
; CHECK-NEXT:    [[CALL_COARSENED_1:%.*]] = tail call noundef zeroext i1 @_Z5test1i(i32 noundef [[CONV6_COARSENED_1]]) #[[ATTR8]]
; CHECK-NEXT:    br label [[OMP_INNER_FOR_BODY_DIVERGENT_ENTRY_DRS_0_INTRO_0:%.*]]
; CHECK:       if.end:
; CHECK-NEXT:    tail call void @_Z4use1i(i32 noundef [[B_0_REG2MEM_1]]) #[[ATTR8]]
; CHECK-NEXT:    tail call void @_Z4use1i(i32 noundef [[B_0_DRS_0:%.*]]) #[[ATTR8]]
; CHECK-NEXT:    [[TMP10]] = add i64 [[COARSENED_STEP]], [[DOTOMP_IV_014]]
; CHECK-NEXT:    [[DOTCOARSENED_1]] = add i64 [[COARSENED_STEP]], [[DOTOMP_IV_014_COARSENED_1]]
; CHECK-NEXT:    [[ADD7:%.*]] = add i64 [[TMP2]], [[DOTOMP_IV_014]]
; CHECK-NEXT:    [[ADD7_COARSENED_1:%.*]] = add i64 [[TMP2]], [[DOTOMP_IV_014_COARSENED_1]]
; CHECK-NEXT:    [[CMP4:%.*]] = icmp ult i64 [[ADD7]], [[ADD]]
; CHECK-NEXT:    [[CMP4_COARSENED_1:%.*]] = icmp ult i64 [[ADD7_COARSENED_1]], [[ADD]]
; CHECK-NEXT:    [[TMP11:%.*]] = icmp ult i64 [[TMP10]], [[ADD]]
; CHECK-NEXT:    [[DOTCOARSENED_12:%.*]] = icmp ult i64 [[DOTCOARSENED_1]], [[ADD]]
; CHECK-NEXT:    [[IS_EPILOGUE_START1:%.*]] = icmp eq i64 [[TMP10]], [[EPILOGUE_START_IV]]
; CHECK-NEXT:    [[IS_EPILOGUE_START1_COARSENED_1:%.*]] = icmp eq i64 [[DOTCOARSENED_1]], [[EPILOGUE_START_IV]]
; CHECK-NEXT:    br i1 [[IS_EPILOGUE_START1]], label [[COARSENED_END_CHECK:%.*]], label [[OMP_INNER_FOR_BODY]], !llvm.loop [[LOOP21:![0-9]+]]
; CHECK:       omp.inner.for.body.divergent.entry.drs.0.intro.0:
; CHECK-NEXT:    br label [[OMP_INNER_FOR_BODY_DIVERGENT_ENTRY_DRS_0:%.*]]
; CHECK:       omp.inner.for.body.divergent.entry.drs.0.intro.1:
; CHECK-NEXT:    br label [[OMP_INNER_FOR_BODY_DIVERGENT_ENTRY_DRS_0]]
; CHECK:       omp.inner.for.body.divergent.entry.drs.0:
; CHECK-NEXT:    [[DR_COARSENED_IDENT_0:%.*]] = phi i32 [ 0, [[OMP_INNER_FOR_BODY_DIVERGENT_ENTRY_DRS_0_INTRO_0]] ], [ 1, [[OMP_INNER_FOR_BODY_DIVERGENT_ENTRY_DRS_0_INTRO_1:%.*]] ]
; CHECK-NEXT:    [[B_0_REG2MEM_1]] = phi i32 [ [[B_0_REG2MEM_0]], [[OMP_INNER_FOR_BODY_DIVERGENT_ENTRY_DRS_0_INTRO_0]] ], [ [[B_0_DRS_0]], [[OMP_INNER_FOR_BODY_DIVERGENT_ENTRY_DRS_0_INTRO_1]] ]
; CHECK-NEXT:    [[CALL_DRS_0_REG2MEM_0:%.*]] = phi i1 [ [[CALL]], [[OMP_INNER_FOR_BODY_DIVERGENT_ENTRY_DRS_0_INTRO_0]] ], [ [[CALL_COARSENED_1]], [[OMP_INNER_FOR_BODY_DIVERGENT_ENTRY_DRS_0_INTRO_1]] ]
; CHECK-NEXT:    br i1 [[CALL_DRS_0_REG2MEM_0]], label [[IF_THEN_DRS_0:%.*]], label [[IF_END_DIVERGENT_EXIT_DRS_0:%.*]]
; CHECK:       if.then.drs.0:
; CHECK-NEXT:    tail call void @_Z4use1Pi(ptr noundef [[A]]) #[[ATTR8]]
; CHECK-NEXT:    br label [[IF_END_DIVERGENT_EXIT_DRS_0]]
; CHECK:       if.end.divergent.exit.drs.0:
; CHECK-NEXT:    [[B_0_DRS_0]] = phi i32 [ 1, [[IF_THEN_DRS_0]] ], [ 0, [[OMP_INNER_FOR_BODY_DIVERGENT_ENTRY_DRS_0]] ]
; CHECK-NEXT:    switch i32 [[DR_COARSENED_IDENT_0]], label [[IF_END_DIVERGENT_EXIT_DRS_0_OUTRO_0:%.*]] [
; CHECK-NEXT:      i32 1, label [[IF_END_DIVERGENT_EXIT_DRS_0_OUTRO_1:%.*]]
; CHECK-NEXT:    ]
; CHECK:       if.end.divergent.exit.drs.0.outro.0:
; CHECK-NEXT:    br label [[OMP_INNER_FOR_BODY_DIVERGENT_ENTRY_DRS_0_INTRO_1]]
; CHECK:       if.end.divergent.exit.drs.0.outro.1:
; CHECK-NEXT:    br label [[IF_END]]
; CHECK:       coarsened.end.check:
; CHECK-NEXT:    br i1 [[TMP11]], label [[OMP_INNER_FOR_BODY_EPILOGUE]], label [[OMP_LOOP_EXIT_LOOPEXIT:%.*]]
; CHECK:       omp.inner.for.body.epilogue:
; CHECK-NEXT:    [[DOTOMP_IV_014_EPILOGUE:%.*]] = phi i64 [ [[TMP10]], [[COARSENED_END_CHECK]] ], [ [[ADD7_EPILOGUE:%.*]], [[IF_END_EPILOGUE:%.*]] ], [ [[TMP1]], [[OMP_INNER_FOR_BODY_LR_PH]] ]
; CHECK-NEXT:    [[CONV6_EPILOGUE:%.*]] = trunc i64 [[DOTOMP_IV_014_EPILOGUE]] to i32
; CHECK-NEXT:    [[CALL_EPILOGUE:%.*]] = tail call noundef zeroext i1 @_Z5test1i(i32 noundef [[CONV6_EPILOGUE]]) #[[ATTR8]]
; CHECK-NEXT:    br i1 [[CALL_EPILOGUE]], label [[IF_THEN_EPILOGUE:%.*]], label [[IF_END_EPILOGUE]]
; CHECK:       if.then.epilogue:
; CHECK-NEXT:    tail call void @_Z4use1Pi(ptr noundef [[A]]) #[[ATTR8]]
; CHECK-NEXT:    br label [[IF_END_EPILOGUE]]
; CHECK:       if.end.epilogue:
; CHECK-NEXT:    [[B_0_EPILOGUE:%.*]] = phi i32 [ 1, [[IF_THEN_EPILOGUE]] ], [ 0, [[OMP_INNER_FOR_BODY_EPILOGUE]] ]
; CHECK-NEXT:    tail call void @_Z4use1i(i32 noundef [[B_0_EPILOGUE]]) #[[ATTR8]]
; CHECK-NEXT:    [[ADD7_EPILOGUE]] = add i64 [[TMP2]], [[DOTOMP_IV_014_EPILOGUE]]
; CHECK-NEXT:    [[CMP4_EPILOGUE:%.*]] = icmp ult i64 [[ADD7_EPILOGUE]], [[ADD]]
; CHECK-NEXT:    br i1 [[CMP4_EPILOGUE]], label [[OMP_INNER_FOR_BODY_EPILOGUE]], label [[OMP_LOOP_EXIT_LOOPEXIT]], !llvm.loop [[LOOP23:![0-9]+]]
; CHECK:       omp.loop.exit.loopexit:
; CHECK-NEXT:    br label [[OMP_LOOP_EXIT]]
; CHECK:       omp.loop.exit:
; CHECK-NEXT:    tail call void @__kmpc_distribute_static_fini(ptr addrspacecast (ptr addrspace(1) @anon.c602dca16a57a4f518a4ba61482bb5a6.2 to ptr), i32 [[TMP0]]) #[[ATTR2]]
; CHECK-NEXT:    call void @llvm.lifetime.end.p5(i64 4, ptr addrspace(5) [[DOTOMP_IS_LAST]]) #[[ATTR2]]
; CHECK-NEXT:    call void @llvm.lifetime.end.p5(i64 8, ptr addrspace(5) [[DOTOMP_STRIDE]]) #[[ATTR2]]
; CHECK-NEXT:    call void @llvm.lifetime.end.p5(i64 8, ptr addrspace(5) [[DOTOMP_UB]]) #[[ATTR2]]
; CHECK-NEXT:    call void @llvm.lifetime.end.p5(i64 8, ptr addrspace(5) [[DOTOMP_LB]]) #[[ATTR2]]
; CHECK-NEXT:    br label [[OMP_PRECOND_END]]
; CHECK:       omp.precond.end:
; CHECK-NEXT:    ret void
;
; DRCHECK-LABEL: define internal void @__omp_offloading_58_36e080__Z6vecaddPii_l19_omp_outlined_omp_outlined(
; DRCHECK-SAME: ptr noalias nocapture noundef readonly [[DOTGLOBAL_TID_:%.*]], ptr noalias nocapture readnone [[DOTBOUND_TID_:%.*]], i64 noundef [[DOTPREVIOUS_LB_:%.*]], i64 noundef [[DOTPREVIOUS_UB_:%.*]], i64 noundef [[SIZE:%.*]], ptr noundef [[A:%.*]]) #[[ATTR3:[0-9]+]] {
; DRCHECK-NEXT:  entry:
; DRCHECK-NEXT:    [[DOTOMP_LB:%.*]] = alloca i64, align 8, addrspace(5)
; DRCHECK-NEXT:    [[DOTOMP_UB:%.*]] = alloca i64, align 8, addrspace(5)
; DRCHECK-NEXT:    [[DOTOMP_STRIDE:%.*]] = alloca i64, align 8, addrspace(5)
; DRCHECK-NEXT:    [[DOTOMP_IS_LAST:%.*]] = alloca i32, align 4, addrspace(5)
; DRCHECK-NEXT:    [[SEXT_MASK:%.*]] = and i64 [[SIZE]], 4294967295
; DRCHECK-NEXT:    [[CMP_NOT:%.*]] = icmp eq i64 [[SEXT_MASK]], 0
; DRCHECK-NEXT:    br i1 [[CMP_NOT]], label [[OMP_PRECOND_END:%.*]], label [[OMP_PRECOND_THEN:%.*]]
; DRCHECK:       omp.precond.then:
; DRCHECK-NEXT:    [[DOTOMP_STRIDE_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTOMP_STRIDE]] to ptr
; DRCHECK-NEXT:    [[DOTOMP_IS_LAST_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTOMP_IS_LAST]] to ptr
; DRCHECK-NEXT:    [[DOTOMP_UB_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTOMP_UB]] to ptr
; DRCHECK-NEXT:    [[DOTOMP_LB_ASCAST:%.*]] = addrspacecast ptr addrspace(5) [[DOTOMP_LB]] to ptr
; DRCHECK-NEXT:    call void @llvm.lifetime.start.p5(i64 8, ptr addrspace(5) [[DOTOMP_LB]]) #[[ATTR2]]
; DRCHECK-NEXT:    call void @llvm.lifetime.start.p5(i64 8, ptr addrspace(5) [[DOTOMP_UB]]) #[[ATTR2]]
; DRCHECK-NEXT:    store i64 [[DOTPREVIOUS_LB_]], ptr addrspace(5) [[DOTOMP_LB]], align 8, !tbaa [[TBAA13]]
; DRCHECK-NEXT:    store i64 [[DOTPREVIOUS_UB_]], ptr addrspace(5) [[DOTOMP_UB]], align 8, !tbaa [[TBAA13]]
; DRCHECK-NEXT:    call void @llvm.lifetime.start.p5(i64 8, ptr addrspace(5) [[DOTOMP_STRIDE]]) #[[ATTR2]]
; DRCHECK-NEXT:    store i64 1, ptr addrspace(5) [[DOTOMP_STRIDE]], align 8, !tbaa [[TBAA13]]
; DRCHECK-NEXT:    call void @llvm.lifetime.start.p5(i64 4, ptr addrspace(5) [[DOTOMP_IS_LAST]]) #[[ATTR2]]
; DRCHECK-NEXT:    store i32 0, ptr addrspace(5) [[DOTOMP_IS_LAST]], align 4, !tbaa [[TBAA17]]
; DRCHECK-NEXT:    [[TMP0:%.*]] = load i32, ptr [[DOTGLOBAL_TID_]], align 4, !tbaa [[TBAA17]]
; DRCHECK-NEXT:    call void @__kmpc_for_static_init_8u(ptr addrspacecast (ptr addrspace(1) @anon.c602dca16a57a4f518a4ba61482bb5a6.3 to ptr), i32 [[TMP0]], i32 33, ptr nocapture nonnull [[DOTOMP_IS_LAST_ASCAST]], ptr nocapture nonnull [[DOTOMP_LB_ASCAST]], ptr nocapture nonnull [[DOTOMP_UB_ASCAST]], ptr nocapture nonnull [[DOTOMP_STRIDE_ASCAST]], i64 1, i64 1) #[[ATTR2]]
; DRCHECK-NEXT:    [[TMP1:%.*]] = load i64, ptr addrspace(5) [[DOTOMP_LB]], align 8, !tbaa [[TBAA13]]
; DRCHECK-NEXT:    [[ADD:%.*]] = add i64 [[DOTPREVIOUS_UB_]], 1
; DRCHECK-NEXT:    [[CMP413:%.*]] = icmp ult i64 [[TMP1]], [[ADD]]
; DRCHECK-NEXT:    br i1 [[CMP413]], label [[OMP_INNER_FOR_BODY_LR_PH:%.*]], label [[OMP_LOOP_EXIT:%.*]]
; DRCHECK:       omp.inner.for.body.lr.ph:
; DRCHECK-NEXT:    [[TMP2:%.*]] = load i64, ptr addrspace(5) [[DOTOMP_STRIDE]], align 8
; DRCHECK-NEXT:    [[INITIAL_IV_COARSENED_1:%.*]] = add i64 [[TMP2]], [[TMP1]]
; DRCHECK-NEXT:    [[COARSENED_STEP:%.*]] = mul i64 [[TMP2]], 2
; DRCHECK-NEXT:    [[TMP3:%.*]] = sub i64 [[ADD]], [[TMP1]]
; DRCHECK-NEXT:    [[TMP4:%.*]] = add i64 [[TMP3]], [[TMP2]]
; DRCHECK-NEXT:    [[TMP5:%.*]] = sub i64 [[TMP4]], 1
; DRCHECK-NEXT:    [[TMP6:%.*]] = udiv i64 [[TMP5]], [[TMP2]]
; DRCHECK-NEXT:    [[TMP7:%.*]] = udiv i64 [[TMP6]], 2
; DRCHECK-NEXT:    [[TMP8:%.*]] = mul nsw i64 [[TMP7]], 2
; DRCHECK-NEXT:    [[TMP9:%.*]] = mul nsw i64 [[TMP8]], [[TMP2]]
; DRCHECK-NEXT:    [[EPILOGUE_START_IV:%.*]] = add i64 [[TMP9]], [[TMP1]]
; DRCHECK-NEXT:    [[IS_EPILOGUE_START:%.*]] = icmp eq i64 [[TMP1]], [[EPILOGUE_START_IV]]
; DRCHECK-NEXT:    br i1 [[IS_EPILOGUE_START]], label [[OMP_INNER_FOR_BODY_EPILOGUE:%.*]], label [[OMP_INNER_FOR_BODY:%.*]]
; DRCHECK:       omp.inner.for.body:
; DRCHECK-NEXT:    [[B_0_REG2MEM_0:%.*]] = phi i32 [ undef, [[OMP_INNER_FOR_BODY_LR_PH]] ], [ [[B_0_REG2MEM_1:%.*]], [[IF_END:%.*]] ]
; DRCHECK-NEXT:    [[DOTOMP_IV_014:%.*]] = phi i64 [ [[TMP1]], [[OMP_INNER_FOR_BODY_LR_PH]] ], [ [[TMP11:%.*]], [[IF_END]] ]
; DRCHECK-NEXT:    [[DOTOMP_IV_014_COARSENED_1:%.*]] = phi i64 [ [[INITIAL_IV_COARSENED_1]], [[OMP_INNER_FOR_BODY_LR_PH]] ], [ [[DOTCOARSENED_1:%.*]], [[IF_END]] ]
; DRCHECK-NEXT:    [[CONV6:%.*]] = trunc i64 [[DOTOMP_IV_014]] to i32
; DRCHECK-NEXT:    [[CONV6_COARSENED_1:%.*]] = trunc i64 [[DOTOMP_IV_014_COARSENED_1]] to i32
; DRCHECK-NEXT:    [[CALL:%.*]] = tail call noundef zeroext i1 @_Z5test1i(i32 noundef [[CONV6]]) #[[ATTR8:[0-9]+]]
; DRCHECK-NEXT:    [[CALL_COARSENED_1:%.*]] = tail call noundef zeroext i1 @_Z5test1i(i32 noundef [[CONV6_COARSENED_1]]) #[[ATTR8]]
; DRCHECK-NEXT:    [[TMP10:%.*]] = icmp eq i1 [[CALL_COARSENED_1]], [[CALL]]
; DRCHECK-NEXT:    br i1 [[TMP10]], label [[OMP_INNER_FOR_BODY_DIVERGENT_ENTRY:%.*]], label [[OMP_INNER_FOR_BODY_DIVERGENT_ENTRY_DRS_0_INTRO_0:%.*]]
; DRCHECK:       omp.inner.for.body.divergent.entry:
; DRCHECK-NEXT:    br i1 [[CALL]], label [[IF_THEN:%.*]], label [[IF_END_DIVERGENT_EXIT:%.*]]
; DRCHECK:       if.then:
; DRCHECK-NEXT:    tail call void @_Z4use1Pi(ptr noundef [[A]]) #[[ATTR8]]
; DRCHECK-NEXT:    tail call void @_Z4use1Pi(ptr noundef [[A]]) #[[ATTR8]]
; DRCHECK-NEXT:    br label [[IF_END_DIVERGENT_EXIT]]
; DRCHECK:       if.end.divergent.exit:
; DRCHECK-NEXT:    [[B_0:%.*]] = phi i32 [ 1, [[IF_THEN]] ], [ 0, [[OMP_INNER_FOR_BODY_DIVERGENT_ENTRY]] ]
; DRCHECK-NEXT:    [[B_0_COARSENED_1:%.*]] = phi i32 [ 1, [[IF_THEN]] ], [ 0, [[OMP_INNER_FOR_BODY_DIVERGENT_ENTRY]] ]
; DRCHECK-NEXT:    br label [[IF_END]]
; DRCHECK:       if.end:
; DRCHECK-NEXT:    [[B_0_COARSENED_1_REG2MEM_0:%.*]] = phi i32 [ [[B_0_COARSENED_1]], [[IF_END_DIVERGENT_EXIT]] ], [ [[B_0_DRS_0:%.*]], [[IF_END_DIVERGENT_EXIT_DRS_0_OUTRO_1:%.*]] ]
; DRCHECK-NEXT:    [[B_0_REG2MEM_1]] = phi i32 [ [[B_0]], [[IF_END_DIVERGENT_EXIT]] ], [ [[B_0_REG2MEM_2:%.*]], [[IF_END_DIVERGENT_EXIT_DRS_0_OUTRO_1]] ]
; DRCHECK-NEXT:    tail call void @_Z4use1i(i32 noundef [[B_0_REG2MEM_1]]) #[[ATTR8]]
; DRCHECK-NEXT:    tail call void @_Z4use1i(i32 noundef [[B_0_COARSENED_1_REG2MEM_0]]) #[[ATTR8]]
; DRCHECK-NEXT:    [[TMP11]] = add i64 [[COARSENED_STEP]], [[DOTOMP_IV_014]]
; DRCHECK-NEXT:    [[DOTCOARSENED_1]] = add i64 [[COARSENED_STEP]], [[DOTOMP_IV_014_COARSENED_1]]
; DRCHECK-NEXT:    [[ADD7:%.*]] = add i64 [[TMP2]], [[DOTOMP_IV_014]]
; DRCHECK-NEXT:    [[ADD7_COARSENED_1:%.*]] = add i64 [[TMP2]], [[DOTOMP_IV_014_COARSENED_1]]
; DRCHECK-NEXT:    [[CMP4:%.*]] = icmp ult i64 [[ADD7]], [[ADD]]
; DRCHECK-NEXT:    [[CMP4_COARSENED_1:%.*]] = icmp ult i64 [[ADD7_COARSENED_1]], [[ADD]]
; DRCHECK-NEXT:    [[TMP12:%.*]] = icmp ult i64 [[TMP11]], [[ADD]]
; DRCHECK-NEXT:    [[DOTCOARSENED_12:%.*]] = icmp ult i64 [[DOTCOARSENED_1]], [[ADD]]
; DRCHECK-NEXT:    [[IS_EPILOGUE_START1:%.*]] = icmp eq i64 [[TMP11]], [[EPILOGUE_START_IV]]
; DRCHECK-NEXT:    [[IS_EPILOGUE_START1_COARSENED_1:%.*]] = icmp eq i64 [[DOTCOARSENED_1]], [[EPILOGUE_START_IV]]
; DRCHECK-NEXT:    br i1 [[IS_EPILOGUE_START1]], label [[COARSENED_END_CHECK:%.*]], label [[OMP_INNER_FOR_BODY]], !llvm.loop [[LOOP21:![0-9]+]]
; DRCHECK:       omp.inner.for.body.divergent.entry.drs.0.intro.0:
; DRCHECK-NEXT:    br label [[OMP_INNER_FOR_BODY_DIVERGENT_ENTRY_DRS_0:%.*]]
; DRCHECK:       omp.inner.for.body.divergent.entry.drs.0.intro.1:
; DRCHECK-NEXT:    br label [[OMP_INNER_FOR_BODY_DIVERGENT_ENTRY_DRS_0]]
; DRCHECK:       omp.inner.for.body.divergent.entry.drs.0:
; DRCHECK-NEXT:    [[DR_COARSENED_IDENT_0:%.*]] = phi i32 [ 0, [[OMP_INNER_FOR_BODY_DIVERGENT_ENTRY_DRS_0_INTRO_0]] ], [ 1, [[OMP_INNER_FOR_BODY_DIVERGENT_ENTRY_DRS_0_INTRO_1:%.*]] ]
; DRCHECK-NEXT:    [[B_0_REG2MEM_2]] = phi i32 [ [[B_0_REG2MEM_0]], [[OMP_INNER_FOR_BODY_DIVERGENT_ENTRY_DRS_0_INTRO_0]] ], [ [[B_0_DRS_0]], [[OMP_INNER_FOR_BODY_DIVERGENT_ENTRY_DRS_0_INTRO_1]] ]
; DRCHECK-NEXT:    [[CALL_DRS_0_REG2MEM_0:%.*]] = phi i1 [ [[CALL]], [[OMP_INNER_FOR_BODY_DIVERGENT_ENTRY_DRS_0_INTRO_0]] ], [ [[CALL_COARSENED_1]], [[OMP_INNER_FOR_BODY_DIVERGENT_ENTRY_DRS_0_INTRO_1]] ]
; DRCHECK-NEXT:    br i1 [[CALL_DRS_0_REG2MEM_0]], label [[IF_THEN_DRS_0:%.*]], label [[IF_END_DIVERGENT_EXIT_DRS_0:%.*]]
; DRCHECK:       if.then.drs.0:
; DRCHECK-NEXT:    tail call void @_Z4use1Pi(ptr noundef [[A]]) #[[ATTR8]]
; DRCHECK-NEXT:    br label [[IF_END_DIVERGENT_EXIT_DRS_0]]
; DRCHECK:       if.end.divergent.exit.drs.0:
; DRCHECK-NEXT:    [[B_0_DRS_0]] = phi i32 [ 1, [[IF_THEN_DRS_0]] ], [ 0, [[OMP_INNER_FOR_BODY_DIVERGENT_ENTRY_DRS_0]] ]
; DRCHECK-NEXT:    switch i32 [[DR_COARSENED_IDENT_0]], label [[IF_END_DIVERGENT_EXIT_DRS_0_OUTRO_0:%.*]] [
; DRCHECK-NEXT:      i32 1, label [[IF_END_DIVERGENT_EXIT_DRS_0_OUTRO_1]]
; DRCHECK-NEXT:    ]
; DRCHECK:       if.end.divergent.exit.drs.0.outro.0:
; DRCHECK-NEXT:    br label [[OMP_INNER_FOR_BODY_DIVERGENT_ENTRY_DRS_0_INTRO_1]]
; DRCHECK:       if.end.divergent.exit.drs.0.outro.1:
; DRCHECK-NEXT:    br label [[IF_END]]
; DRCHECK:       coarsened.end.check:
; DRCHECK-NEXT:    br i1 [[TMP12]], label [[OMP_INNER_FOR_BODY_EPILOGUE]], label [[OMP_LOOP_EXIT_LOOPEXIT:%.*]]
; DRCHECK:       omp.inner.for.body.epilogue:
; DRCHECK-NEXT:    [[DOTOMP_IV_014_EPILOGUE:%.*]] = phi i64 [ [[TMP11]], [[COARSENED_END_CHECK]] ], [ [[ADD7_EPILOGUE:%.*]], [[IF_END_EPILOGUE:%.*]] ], [ [[TMP1]], [[OMP_INNER_FOR_BODY_LR_PH]] ]
; DRCHECK-NEXT:    [[CONV6_EPILOGUE:%.*]] = trunc i64 [[DOTOMP_IV_014_EPILOGUE]] to i32
; DRCHECK-NEXT:    [[CALL_EPILOGUE:%.*]] = tail call noundef zeroext i1 @_Z5test1i(i32 noundef [[CONV6_EPILOGUE]]) #[[ATTR8]]
; DRCHECK-NEXT:    br i1 [[CALL_EPILOGUE]], label [[IF_THEN_EPILOGUE:%.*]], label [[IF_END_EPILOGUE]]
; DRCHECK:       if.then.epilogue:
; DRCHECK-NEXT:    tail call void @_Z4use1Pi(ptr noundef [[A]]) #[[ATTR8]]
; DRCHECK-NEXT:    br label [[IF_END_EPILOGUE]]
; DRCHECK:       if.end.epilogue:
; DRCHECK-NEXT:    [[B_0_EPILOGUE:%.*]] = phi i32 [ 1, [[IF_THEN_EPILOGUE]] ], [ 0, [[OMP_INNER_FOR_BODY_EPILOGUE]] ]
; DRCHECK-NEXT:    tail call void @_Z4use1i(i32 noundef [[B_0_EPILOGUE]]) #[[ATTR8]]
; DRCHECK-NEXT:    [[ADD7_EPILOGUE]] = add i64 [[TMP2]], [[DOTOMP_IV_014_EPILOGUE]]
; DRCHECK-NEXT:    [[CMP4_EPILOGUE:%.*]] = icmp ult i64 [[ADD7_EPILOGUE]], [[ADD]]
; DRCHECK-NEXT:    br i1 [[CMP4_EPILOGUE]], label [[OMP_INNER_FOR_BODY_EPILOGUE]], label [[OMP_LOOP_EXIT_LOOPEXIT]], !llvm.loop [[LOOP23:![0-9]+]]
; DRCHECK:       omp.loop.exit.loopexit:
; DRCHECK-NEXT:    br label [[OMP_LOOP_EXIT]]
; DRCHECK:       omp.loop.exit:
; DRCHECK-NEXT:    tail call void @__kmpc_distribute_static_fini(ptr addrspacecast (ptr addrspace(1) @anon.c602dca16a57a4f518a4ba61482bb5a6.2 to ptr), i32 [[TMP0]]) #[[ATTR2]]
; DRCHECK-NEXT:    call void @llvm.lifetime.end.p5(i64 4, ptr addrspace(5) [[DOTOMP_IS_LAST]]) #[[ATTR2]]
; DRCHECK-NEXT:    call void @llvm.lifetime.end.p5(i64 8, ptr addrspace(5) [[DOTOMP_STRIDE]]) #[[ATTR2]]
; DRCHECK-NEXT:    call void @llvm.lifetime.end.p5(i64 8, ptr addrspace(5) [[DOTOMP_UB]]) #[[ATTR2]]
; DRCHECK-NEXT:    call void @llvm.lifetime.end.p5(i64 8, ptr addrspace(5) [[DOTOMP_LB]]) #[[ATTR2]]
; DRCHECK-NEXT:    br label [[OMP_PRECOND_END]]
; DRCHECK:       omp.precond.end:
; DRCHECK-NEXT:    ret void
;
entry:
  %.omp.lb = alloca i64, align 8, addrspace(5)
  %.omp.ub = alloca i64, align 8, addrspace(5)
  %.omp.stride = alloca i64, align 8, addrspace(5)
  %.omp.is_last = alloca i32, align 4, addrspace(5)
  %sext.mask = and i64 %size, 4294967295
  %cmp.not = icmp eq i64 %sext.mask, 0
  br i1 %cmp.not, label %omp.precond.end, label %omp.precond.then

omp.precond.then:                                 ; preds = %entry
  %.omp.stride.ascast = addrspacecast ptr addrspace(5) %.omp.stride to ptr
  %.omp.is_last.ascast = addrspacecast ptr addrspace(5) %.omp.is_last to ptr
  %.omp.ub.ascast = addrspacecast ptr addrspace(5) %.omp.ub to ptr
  %.omp.lb.ascast = addrspacecast ptr addrspace(5) %.omp.lb to ptr
  call void @llvm.lifetime.start.p5(i64 8, ptr addrspace(5) %.omp.lb) #2
  call void @llvm.lifetime.start.p5(i64 8, ptr addrspace(5) %.omp.ub) #2
  store i64 %.previous.lb., ptr addrspace(5) %.omp.lb, align 8, !tbaa !13
  store i64 %.previous.ub., ptr addrspace(5) %.omp.ub, align 8, !tbaa !13
  call void @llvm.lifetime.start.p5(i64 8, ptr addrspace(5) %.omp.stride) #2
  store i64 1, ptr addrspace(5) %.omp.stride, align 8, !tbaa !13
  call void @llvm.lifetime.start.p5(i64 4, ptr addrspace(5) %.omp.is_last) #2
  store i32 0, ptr addrspace(5) %.omp.is_last, align 4, !tbaa !17
  %0 = load i32, ptr %.global_tid., align 4, !tbaa !17
  call void @__kmpc_for_static_init_8u(ptr addrspacecast (ptr addrspace(1) @anon.c602dca16a57a4f518a4ba61482bb5a6.3 to ptr), i32 %0, i32 33, ptr nocapture nonnull %.omp.is_last.ascast, ptr nocapture nonnull %.omp.lb.ascast, ptr nocapture nonnull %.omp.ub.ascast, ptr nocapture nonnull %.omp.stride.ascast, i64 1, i64 1) #2
  %1 = load i64, ptr addrspace(5) %.omp.lb, align 8, !tbaa !13
  %add = add i64 %.previous.ub., 1
  %cmp413 = icmp ult i64 %1, %add
  br i1 %cmp413, label %omp.inner.for.body.lr.ph, label %omp.loop.exit

omp.inner.for.body.lr.ph:                         ; preds = %omp.precond.then
  %2 = load i64, ptr addrspace(5) %.omp.stride, align 8
  br label %omp.inner.for.body

omp.inner.for.body:                               ; preds = %if.end, %omp.inner.for.body.lr.ph
  %.omp.iv.014 = phi i64 [ %1, %omp.inner.for.body.lr.ph ], [ %add7, %if.end ]
  %conv6 = trunc i64 %.omp.iv.014 to i32
  %call = tail call noundef zeroext i1 @_Z5test1i(i32 noundef %conv6) #8
  br i1 %call, label %if.then, label %if.end

if.then:                                          ; preds = %omp.inner.for.body
  tail call void @_Z4use1Pi(ptr noundef %a) #8
  br label %if.end

if.end:                                           ; preds = %if.then, %omp.inner.for.body
  %b.0 = phi i32 [ 1, %if.then ], [ 0, %omp.inner.for.body ]
  tail call void @_Z4use1i(i32 noundef %b.0) #8
  %add7 = add i64 %2, %.omp.iv.014
  %cmp4 = icmp ult i64 %add7, %add
  br i1 %cmp4, label %omp.inner.for.body, label %omp.loop.exit, !llvm.loop !45

omp.loop.exit:                                    ; preds = %if.end, %omp.precond.then
  tail call void @__kmpc_distribute_static_fini(ptr addrspacecast (ptr addrspace(1) @anon.c602dca16a57a4f518a4ba61482bb5a6.2 to ptr), i32 %0) #2
  call void @llvm.lifetime.end.p5(i64 4, ptr addrspace(5) %.omp.is_last) #2
  call void @llvm.lifetime.end.p5(i64 8, ptr addrspace(5) %.omp.stride) #2
  call void @llvm.lifetime.end.p5(i64 8, ptr addrspace(5) %.omp.ub) #2
  call void @llvm.lifetime.end.p5(i64 8, ptr addrspace(5) %.omp.lb) #2
  br label %omp.precond.end

omp.precond.end:                                  ; preds = %omp.loop.exit, %entry
  ret void
}

; Function Attrs: nounwind
declare void @__kmpc_for_static_init_8u(ptr, i32, i32, ptr nocapture nofree, ptr nocapture nofree, ptr nocapture nofree, ptr nocapture nofree, i64, i64) local_unnamed_addr #2

; Function Attrs: convergent
declare noundef zeroext i1 @_Z5test1i(i32 noundef) local_unnamed_addr #4

; Function Attrs: convergent
declare void @_Z4use1Pi(ptr noundef) local_unnamed_addr #4

; Function Attrs: convergent
declare void @_Z4use1i(i32 noundef) local_unnamed_addr #4

; Function Attrs: nounwind
declare void @__kmpc_distribute_static_fini(ptr, i32) local_unnamed_addr #2

; Function Attrs: alwaysinline
declare void @__kmpc_parallel_51(ptr, i32, i32, i32, i32, ptr, ptr, ptr, i64) local_unnamed_addr #5

; Function Attrs: nounwind
declare i32 @__kmpc_global_thread_num(ptr) local_unnamed_addr #2

declare void @__kmpc_target_deinit() local_unnamed_addr

; Function Attrs: nocallback nofree nosync nounwind speculatable willreturn memory(none)
declare i64 @llvm.umin.i64(i64, i64) #6

attributes #0 = { alwaysinline norecurse nounwind "amdgpu-flat-work-group-size"="1,256" "kernel" "no-trapping-math"="true" "omp_target_thread_limit"="256" "stack-protector-buffer-size"="8" "target-cpu"="gfx906" "target-features"="+16-bit-insts,+ci-insts,+dl-insts,+dot1-insts,+dot10-insts,+dot2-insts,+dot7-insts,+dpp,+gfx8-insts,+gfx9-insts,+s-memrealtime,+s-memtime-inst,+wavefrontsize64" "uniform-work-group-size"="true" }
attributes #1 = { nocallback nofree nosync nounwind willreturn memory(argmem: readwrite) }
attributes #2 = { nounwind }
attributes #3 = { alwaysinline convergent norecurse nounwind "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="gfx906" "target-features"="+16-bit-insts,+ci-insts,+dl-insts,+dot1-insts,+dot10-insts,+dot2-insts,+dot7-insts,+dpp,+gfx8-insts,+gfx9-insts,+s-memrealtime,+s-memtime-inst,+wavefrontsize64" }
attributes #4 = { convergent "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="gfx906" "target-features"="+16-bit-insts,+ci-insts,+dl-insts,+dot1-insts,+dot10-insts,+dot2-insts,+dot7-insts,+dpp,+gfx8-insts,+gfx9-insts,+s-memrealtime,+s-memtime-inst,+wavefrontsize64" }
attributes #5 = { alwaysinline }
attributes #6 = { nocallback nofree nosync nounwind speculatable willreturn memory(none) }
attributes #7 = { nounwind memory(readwrite) }
attributes #8 = { convergent nounwind }

!omp_offload.info = !{!0}
!nvvm.annotations = !{!1}
!llvm.module.flags = !{!2, !3, !4, !5, !6, !7, !8, !9}
!opencl.ocl.version = !{!10}
!llvm.ident = !{!11, !12}

!0 = !{i32 0, i32 88, i32 3596416, !"_Z6vecaddPii", i32 19, i32 0, i32 0}
!1 = !{ptr @__omp_offloading_58_36e080__Z6vecaddPii_l19, !"kernel", i32 1}
!2 = !{i32 1, !"amdgpu_code_object_version", i32 400}
!3 = !{i32 1, !"wchar_size", i32 4}
!4 = !{i32 7, !"openmp", i32 51}
!5 = !{i32 7, !"openmp-device", i32 51}
!6 = !{i32 8, !"PIC Level", i32 2}
!7 = !{i32 4, !"amdgpu_hostcall", i32 1}
!8 = !{i32 1, !"ThinLTO", i32 0}
!9 = !{i32 1, !"EnableSplitLTOUnit", i32 1}
!10 = !{i32 2, i32 0}
!11 = !{!"clang version 18.0.0 (git@github.com:ivanradanov/llvm-project2.git 15032ed8568f4cc6773be914c054cb601ba65bc9)"}
!12 = !{!"AMD clang version 17.0.0 (https://github.com/RadeonOpenCompute/llvm-project roc-5.7.0 23352 d1e13c532a947d0cbfc94759c00dcf152294aa13)"}
!13 = !{!14, !14, i64 0}
!14 = !{!"long", !15, i64 0}
!15 = !{!"omnipotent char", !16, i64 0}
!16 = !{!"Simple C++ TBAA"}
!17 = !{!18, !18, i64 0}
!18 = !{!"int", !15, i64 0}
!19 = !{!20, !20, i64 0}
!20 = !{!"any pointer", !15, i64 0}
!45 = distinct !{!45, !46}
!46 = !{!"llvm.loop.unroll_and_interleave.count", i32 2}
